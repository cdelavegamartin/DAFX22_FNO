{"cells":[{"cell_type":"markdown","metadata":{"id":"03H-ziQi4h9K"},"source":["Install py-pde library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3UsgXASgSo1"},"outputs":[],"source":["%pip install py-pde"]},{"cell_type":"markdown","metadata":{"id":"7mOpoZ_m8muk"},"source":["Generate dataset"]},{"cell_type":"markdown","metadata":{"id":"8rYTlCKzEO2_"},"source":["## Basic Parameter Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zoWZoPpOEO2_"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","f = 4410      # sampling frequency  \n","T = 1/f        # sampling time \n","dur = 0.1       # simulation duration\n","\n","t = np.arange(0, dur+T/2, T) # 0:T:dur;    # time vector \n","\n","l = 2          # length of the pipe \n","dx = 1e-2      # spatial stepsize \n","xs = np.arange(0, l+dx/2, dx) # 0:dx:l;    # space vector \n","numXs = np.size(xs)\n","\n","#c0 = 340\n","c0 = 30       # propagation speed"]},{"cell_type":"markdown","metadata":{"id":"gAnjmJJcEO3A"},"source":["## FTM Stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5g_6KX23EO3A"},"outputs":[],"source":["Mu = 250       # number of eigenvalues \n","mu = np.arange(1, Mu+1) # 1:Mu;    \n","\n","test = 1j*c0*mu*np.pi/l\n","\n","gmu = np.concatenate((mu*np.pi/l, mu*np.pi/l))\n","smu = np.concatenate((1j*c0*mu*np.pi/l, -1j*c0*mu*np.pi/l))\n","\n","K1 = lambda x: 1j*np.sin(gmu*x) # @(x) 1j*sin(gmu*x); \n","K2 = lambda x: 1j*smu*np.sin(gmu*x)\n","Ka1 = lambda x: 1j/c0**2*np.conj(smu)*np.sin(gmu*x)\n","Ka2 = lambda x: 1j*np.sin(gmu*x)\n","\n","nmu = 1./(l/2*(c0**2*smu + np.conj(smu)))\n","\n","A = np.diag(np.exp(smu*T)); \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJXPzuB-EO3B"},"outputs":[],"source":["xeVec = np.array([0.1*l, 0.2*l, 0.3*l]) # vector of excitaion positions (can be extended) \n","\n","num_param_steps = 1323\n","field_values = np.linspace(0,10,num_param_steps)\n","grid_size = numXs\n","\n","training_input = torch.zeros(num_param_steps, grid_size,2)\n","training_output = torch.zeros(num_param_steps, grid_size,1)\n","\n","# grid = CartesianGrid([[0, 1]], grid_size, periodic=False)\n","\n","index = 0\n","\n","for xe, xeVal in enumerate(xeVec): #for xe = 1:length(xeVec)\n","    # Excitation for the wave equation is a simple delta-impulse at\n","    # position xe\n","    # Possible extensions: \n","    # - exciation by a hamming window to have a more smooth excitation \n","    # - combination with a temporal exciation shape \n","    yi = Ka2(xeVal)*T; # set initial values for states\n","    \n","    # vectors \n","    ybar = np.zeros((2*Mu, np.size(t)),dtype=complex); \n","    \n","    # set initial states\n","    ybar[:,0] = yi; \n","    \n","    test = range(1,np.size(t))\n","    \n","    # processing to create time progression of individual states\n","    for k in range(1,np.size(t)) :\n","        ybar[:,k] = A@ybar[:,k-1]\n","    \n","    \n","    # create output signal over time at a single observation position\n","    # (maybe this part is not necessary, therefore it is commented)\n","    xo = 0.7*l; \n","    c1 = K1(xo); \n","    y = c1@ybar; # recover deflection from states (inverse transformation)\n","    y = np.real(y)\n","    \n","    \n","    # create spatial vectors. \n","    # Result y_x: spatial distribution of the deflection y on the pipe at all\n","    # temportal sampling points\n","    \n","    K1_x = np.zeros((np.size(xs), 2*Mu)); \n","    y_x = np.zeros((np.size(xs), np.size(t))); \n","\n","    for xi in range(np.size(xs)) : #1:length(xs) \n","        K1_x[xi,:] = K1(xs[xi])/nmu; \n","        y_x[xi,:] = K1_x[xi,:]@ybar; \n","    \n","    # take the real part because there might be a small imaginary part \n","    y_x = np.real(y_x) \n","    y_x = y_x / 10**6 # scale the output to less than 1\n","\n","    for k in range(1,np.size(t)) :\n","        #field = ScalarField(grid, val)\n","        #result = solve_poisson_equation(field, bc=[{\"value\": 0}, {\"derivative\": 1}])\n","        training_input[index,:,0] = torch.tensor(y_x[:,k-1])\n","        training_input[index,:,1] = torch.linspace(0,1, grid_size)\n","        training_output[index,:,0] = torch.tensor(y_x[:,k])\n","        index += 1\n","\n","print(index)"]},{"cell_type":"markdown","metadata":{"id":"7p3PZyoD75Rm"},"source":["Model definitions copied from https://github.com/zongyi-li/fourier_neural_operator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUxZF0Zr7248"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","################################################################\n","#  1d fourier layer\n","################################################################\n","class SpectralConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, modes1):\n","        super(SpectralConv1d, self).__init__()\n","\n","        \"\"\"\n","        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n","        \"\"\"\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n","\n","        self.scale = (1 / (in_channels*out_channels))\n","        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n","\n","    # Complex multiplication\n","    def compl_mul1d(self, input, weights):\n","        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n","        return torch.einsum(\"bix,iox->box\", input, weights)\n","\n","    def forward(self, x):\n","        batchsize = x.shape[0]\n","        #Compute Fourier coeffcients up to factor of e^(- something constant)\n","        x_ft = torch.fft.rfft(x)\n","\n","        # Multiply relevant Fourier modes\n","        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n","        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n","\n","        #Return to physical space\n","        x = torch.fft.irfft(out_ft, n=x.size(-1))\n","        return x\n","\n","class FNO1d(nn.Module):\n","    def __init__(self, modes, width):\n","        super(FNO1d, self).__init__()\n","\n","        \"\"\"\n","        The overall network. It contains 4 layers of the Fourier layer.\n","        1. Lift the input to the desire channel dimension by self.fc0 .\n","        2. 4 layers of the integral operators u' = (W + K)(u).\n","            W defined by self.w; K defined by self.conv .\n","        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n","        \n","        input: the solution of the initial condition and location (a(x), x)\n","        input shape: (batchsize, x=s, c=2)\n","        output: the solution of a later timestep\n","        output shape: (batchsize, x=s, c=1)\n","        \"\"\"\n","\n","        self.modes1 = modes\n","        self.width = width\n","        self.padding = 2 # pad the domain if input is non-periodic\n","        self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n","\n","        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.w0 = nn.Conv1d(self.width, self.width, 1)\n","        self.w1 = nn.Conv1d(self.width, self.width, 1)\n","        self.w2 = nn.Conv1d(self.width, self.width, 1)\n","        self.w3 = nn.Conv1d(self.width, self.width, 1)\n","\n","        self.fc1 = nn.Linear(self.width, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        x = self.fc0(x)\n","        x = x.permute(0, 2, 1)\n","        # x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n","\n","        x1 = self.conv0(x)\n","        x2 = self.w0(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv1(x)\n","        x2 = self.w1(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv2(x)\n","        x2 = self.w2(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv3(x)\n","        x2 = self.w3(x)\n","        x = F.gelu(x1) + x2\n","\n","        # x = x[..., :-self.padding] # pad the domain if input is non-periodic\n","        x = x.permute(0, 2, 1)\n","        x = self.fc1(x)\n","        x = F.gelu(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qd_5TzJUIgeE"},"outputs":[],"source":["modes = 32 # 32\n","width = 16 # 16\n","\n","epochs = 1000\n","learning_rate = 1e-4\n","batch_size = 64\n","\n","\n","model = FNO1d(modes, width).to('cuda')\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 1e-3, epochs=epochs, steps_per_epoch= 32)\n","\n","dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(training_input, training_output), batch_size=batch_size, shuffle=True)\n","\n","\n","for ep in range(epochs):\n","  for input, output in dataloader:\n","    input, output = input.cuda(), output.cuda()\n","    optimizer.zero_grad()\n","    pred_output = model(input)\n","    loss = torch.nn.functional.mse_loss(pred_output, output)\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","  print(\"\\r\",'epochs:' + str(ep) + ', loss:' + str(loss.detach().cpu().numpy()), end = \"\")\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"cFmbHcFFCPlM"},"source":["Check output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fze7k5RAgBf"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","grid_start = 0\n","grid_end = 1\n","test_grid_size = 64\n","field_val = 2\n","\n","model_input = torch.zeros(1,grid_size,2)\n","model_output = torch.zeros(1,grid_size,1)\n","\n","testNum = 50\n","model_input[:,:,:] = training_input[testNum,:,:]\n","model_output[:,:,:] = training_output[testNum,:,:]\n","input_field =  model_input[0,:,0] # training_input[10,:,0]\n","model_input = model_input.to('cuda')\n","\n","timeSteps = 2\n","model_output[:,:,:] = training_output[testNum+timeSteps-1,:,:]\n","for _ in range(timeSteps): # repeatedly predict next step \n","  model_result = model(model_input)\n","  model_input[:,:,0] = model_result[:,:,0]\n","  \n","loss = torch.nn.functional.mse_loss(model_result, model_output.to('cuda'))\n","print(\"\\r\",'loss:' + str(loss.detach().cpu().numpy()), end = \"\")\n","\n","plt.figure()\n","plt.plot(input_field.data)\n","plt.plot(model_output[0,:,0].data + 0.2)\n","plt.plot(model_result.detach().cpu().flatten().numpy() + 0.4)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NeuralOperators-WaveMarkov.ipynb","private_outputs":true,"provenance":[{"file_id":"1iz-ZR8dtWNh7MqrtQCvzEmtlmfDot2Vq","timestamp":1643662211045}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}