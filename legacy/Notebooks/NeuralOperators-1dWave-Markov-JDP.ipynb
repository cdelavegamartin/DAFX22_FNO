{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuralOperators-1dWave-Markov-JDP.ipynb","private_outputs":true,"provenance":[{"file_id":"1iz-ZR8dtWNh7MqrtQCvzEmtlmfDot2Vq","timestamp":1643380905142}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Install py-pde library"],"metadata":{"id":"03H-ziQi4h9K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3UsgXASgSo1"},"outputs":[],"source":["!pip install py-pde"]},{"cell_type":"markdown","source":["Generate dataset"],"metadata":{"id":"7mOpoZ_m8muk"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","f = 4410      # sampling frequency  \n","T = 1/f        # sampling time \n","dur = 0.01       # simulation duration\n","\n","t = np.arange(0, dur+T/2, T) # 0:T:dur;    # time vector \n","seq_length = len(t)\n","\n","l = 5          # length of the pipe \n","dx = 1e-2      # spatial stepsize \n","xs = np.arange(0, l+dx/2, dx) # 0:dx:l;    # space vector \n","numXs = np.size(xs)\n","\n","c0 = 340\n","#c0 = 30       # propagation speed\n","\n","Mu = 250       # number of eigenvalues \n","mu = np.arange(1, Mu+1) # 1:Mu;\n","\n","num_variations = 1\n","\n","xeVec = l * np.random.rand(num_variations) # np.array([0.1*l, 0.2*l, 0.3*l]) # vector of excitaion positions (can be extended) \n","\n","training_input = torch.zeros (num_variations, 1, numXs, 2)\n","training_output = torch.zeros(num_variations, seq_length -2 , numXs, 1)\n","\n","test = 1j*c0*mu*np.pi/l\n","\n","gmu = np.concatenate((mu*np.pi/l, mu*np.pi/l))\n","smu = np.concatenate((1j*c0*mu*np.pi/l, -1j*c0*mu*np.pi/l))\n","\n","K1 = lambda x: 1j*np.sin(gmu*x) # @(x) 1j*sin(gmu*x); \n","K2 = lambda x: 1j*smu*np.sin(gmu*x)\n","Ka1 = lambda x: 1j/c0**2*np.conj(smu)*np.sin(gmu*x)\n","Ka2 = lambda x: 1j*np.sin(gmu*x)\n","\n","nmu = 1./(l/2*(c0**2*smu + np.conj(smu)))\n","\n","A = np.diag(np.exp(smu*T)); \n","\n","for xe, xeVal in enumerate(xeVec): #for xe = 1:length(xeVec)\n","    \n","    # Excitation for the wave equation is a simple delta-impulse at\n","    # position xe\n","    # Possible extensions: \n","    # - exciation by a hamming window to have a more smooth excitation \n","    # - combination with a temporal exciation shape \n","    yi = Ka2(xeVal)*T; # set initial values for states\n","    \n","    # vectors \n","    ybar = np.zeros((2*Mu, np.size(t)),dtype=complex); \n","    \n","    # set initial states\n","    ybar[:,0] = yi; \n","    \n","    test = range(1,np.size(t))\n","    \n","    # processing to create time progression of individual states\n","    for k in range(1,np.size(t)) :\n","        ybar[:,k] = A@ybar[:,k-1]\n","    \n","    \n","    # create output signal over time at a single observation position\n","    # (maybe this part is not necessary, therefore it is commented)\n","    xo = 0.7*l; \n","    c1 = K1(xo); \n","    y = c1@ybar; # recover deflection from states (inverse transformation)\n","    y = np.real(y)\n","    \n","    \n","    # create spatial vectors. \n","    # Result y_x: spatial distribution of the deflection y on the pipe at all\n","    # temportal sampling points\n","    \n","    K1_x = np.zeros((np.size(xs), 2*Mu)); \n","    y_x = np.zeros((np.size(xs), np.size(t))); \n","\n","    for xi in range(np.size(xs)) : #1:length(xs) \n","        K1_x[xi,:] = K1(xs[xi])/nmu; \n","        y_x[xi,:] = K1_x[xi,:]@ybar; \n","    \n","    # take the real part because there might be a small imaginary part \n","    y_x = np.real(y_x); \n","    y_x = y_x / y_x.std();\n","\n","    training_input[xe,:,:,:] = torch.tensor(np.stack([y_x[:,1], xs], axis = -1 )).unsqueeze(0)\n","    training_output[xe,:,:,:] = torch.tensor(y_x[:,2:].transpose()).unsqueeze(-1)"],"metadata":{"id":"XsX4QH6HjsAP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model definitions copied from https://github.com/zongyi-li/fourier_neural_operator"],"metadata":{"id":"7p3PZyoD75Rm"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","################################################################\n","#  1d fourier layer\n","################################################################\n","class SpectralConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, modes1):\n","        super(SpectralConv1d, self).__init__()\n","\n","        \"\"\"\n","        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n","        \"\"\"\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n","\n","        self.scale = (1 / (in_channels*out_channels))\n","        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n","\n","    # Complex multiplication\n","    def compl_mul1d(self, input, weights):\n","        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n","        return torch.einsum(\"bix,iox->box\", input, weights)\n","\n","    def forward(self, x):\n","        batchsize = x.shape[0]\n","        #Compute Fourier coeffcients up to factor of e^(- something constant)\n","        x_ft = torch.fft.rfft(x)\n","\n","        # Multiply relevant Fourier modes\n","        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n","        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n","\n","        #Return to physical space\n","        x = torch.fft.irfft(out_ft, n=x.size(-1))\n","        return x\n","\n","class FNO1d(nn.Module):\n","    def __init__(self, modes, width):\n","        super(FNO1d, self).__init__()\n","\n","        \"\"\"\n","        The overall network. It contains 4 layers of the Fourier layer.\n","        1. Lift the input to the desire channel dimension by self.fc0 .\n","        2. 4 layers of the integral operators u' = (W + K)(u).\n","            W defined by self.w; K defined by self.conv .\n","        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n","        \n","        input: the solution of the initial condition and location (a(x), x)\n","        input shape: (batchsize, x=s, c=2)\n","        output: the solution of a later timestep\n","        output shape: (batchsize, x=s, c=1)\n","        \"\"\"\n","\n","        self.modes1 = modes\n","        self.width = width\n","        self.padding = 2 # pad the domain if input is non-periodic\n","        self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n","\n","        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n","        self.w0 = nn.Conv1d(self.width, self.width, 1)\n","        self.w1 = nn.Conv1d(self.width, self.width, 1)\n","        self.w2 = nn.Conv1d(self.width, self.width, 1)\n","        self.w3 = nn.Conv1d(self.width, self.width, 1)\n","\n","        self.fc1 = nn.Linear(self.width, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        x = self.fc0(x)\n","        x = x.permute(0, 2, 1)\n","        # x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n","\n","        x1 = self.conv0(x)\n","        x2 = self.w0(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv1(x)\n","        x2 = self.w1(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv2(x)\n","        x2 = self.w2(x)\n","        x = F.gelu(x1) + x2\n","\n","        x1 = self.conv3(x)\n","        x2 = self.w3(x)\n","        x = F.gelu(x1) + x2\n","\n","        # x = x[..., :-self.padding] # pad the domain if input is non-periodic\n","        x = x.permute(0, 2, 1)\n","        x = self.fc1(x)\n","        x = F.gelu(x)\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"HUxZF0Zr7248"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","modes = 250\n","width = 64\n","\n","epochs = 100\n","learning_rate = 1e-4\n","batch_size = 16\n","\n","model = FNO1d(modes, width).to('cuda')\n","\n","dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(training_input, training_output), batch_size=batch_size, shuffle=True)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 5e-3, epochs=epochs, steps_per_epoch = len(dataloader))\n","\n","\n","for ep in range(epochs):\n","  for input, output in dataloader:\n","    input, output = input.cuda(), output.cuda()\n","    optimizer.zero_grad()\n","\n","    num_time_steps = output.shape[1]\n","    model_input = input[:,0,:,:]\n","    pred_output = torch.zeros(output.shape).cuda()\n","\n","    for i in range(num_time_steps):\n","      model_input = torch.cat([model(model_input), model_input[:,:,1].unsqueeze(-1)], dim = -1)\n","      pred_output[:,i,:,0] = model_input[:,:,0]\n","\n","\n","    loss = torch.nn.functional.mse_loss(pred_output, output)\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","  print(\"\\r\",'epochs:' + str(ep) + ', loss:' + str(loss.detach().cpu().numpy()), end = \"\")\n","  \n"],"metadata":{"id":"qd_5TzJUIgeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check output"],"metadata":{"id":"cFmbHcFFCPlM"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","num_test_time_steps = 100\n","\n","model_input = torch.zeros(1,numXs,2).to('cuda')\n","model_input[:,100,:] = 1\n","output_sequence = torch.zeros((num_test_time_steps,numXs))\n","\n","for i in range(num_test_time_steps):\n","  model_input[:,:,0] = model(model_input)[:,:,0]\n","  output_sequence[i,:] = model_input[:,:,0]\n","\n","plt.figure(figsize = (20,5))\n","plt.imshow(output_sequence.detach().cpu().numpy())\n","plt.figure(figsize = (20,5))\n","plt.plot(output_sequence[0,:].detach().cpu().numpy())"],"metadata":{"id":"7fze7k5RAgBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (20,5))\n","plt.imshow(training_output[0,:,:,0])"],"metadata":{"id":"VnxBp4Gd5aFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(training_input[0,0,:,0].detach().cpu().numpy())"],"metadata":{"id":"YWRp2TlvITRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_input = input[:,0,:,:]\n","#model_input = torch.cat([model(model_input), model_input[:,:,1].unsqueeze(-1)], dim = -1)\n","#model_input = torch.cat([model(model_input), model_input[:,:,1].unsqueeze(-1)], dim = -1)\n","plt.plot(model_input[0,:,0].detach().cpu().numpy())\n","#plt.plot(torch.cat([model(model_input), model_input[:,:,1].unsqueeze(-1)], dim = -1)[0,:,0].detach().cpu().numpy())"],"metadata":{"id":"RrLFWPliSAis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"30bq2zXeSEYb"},"execution_count":null,"outputs":[]}]}